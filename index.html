<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Align Before You Act: Reasoning-Action Alignment
via Runtime Steering for Vision-Language-Action Models">
  <meta name="keywords" content="SEAL">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SEAL</title>
  
  <script>
	window.dataLayer = window.dataLayer || [];

	function gtag() {
	  dataLayer.push(arguments);
	}

	gtag('js', new Date());

	gtag('config', 'G-PYVRSFMDRL');
	
	// Change Video
	const successObjectList = [
		"./static/demos/success/black-mug",
		"./static/demos/success/blue-cup",
		"./static/demos/success/box",
		"./static/demos/success/hook",
		"./static/demos/success/milk-carton",
		"./static/demos/success/red-bottle",
		"./static/demos/success/red-mug",
		"./static/demos/success/toy-block",
		"./static/demos/success/toy-bridge",
		"./static/demos/success/wood-block",
	];
	  
	const failureObjectList = [
		"./static/videos/failure_world_model",
		"./static/videos/narration_failure",
		"./static/videos/behavior_wrong"
	];
	
	const simObjectList = [
		"./static/demos/sim/tape",
		"./static/demos/sim/cup",
		"./static/demos/sim/cube",
		"./static/demos/sim/pillbottle",
		"./static/demos/sim/teapot",
	]
	  
	const failureTextList = [
		"In this example, the actual execution of the action plan knocks the cup down on the table while the world model mistakenly imagines the robot successfully picks up the cup from the table via the handle.",
		"In this example, the actual execution matches the world model's imagination as the robot picks up the chip bag via the edge but the VLM generates a wrong behavior narration, saying that the robot fails to pick up the bag.",
		"In this example, the behavior narrations generated by the VLM are accurate, but the VLM selects the wrong action plan with the wrong reasoning given the task description."
	];
	  
	function switchSuccessVideo() {
		var object = document.successObjectForm.switch.options[document.successObjectForm.switch.selectedIndex].value;
		var videoList = Array();
		
//		document.getElementById("test_text").textContent= "abc";
		document.getElementById("real_video_success").src = successObjectList[object] + ".mp4";
//		document.getElementById("real_plot_success").src = successObjectList[object] + ".html";
//		document.getElementById("test_text").textContent= successObjectList[object];
	}
	  
	function switchFailureVideo() {
		var object = document.failureObjectForm.switch.options[document.failureObjectForm.switch.selectedIndex].value;
		var videoList = Array();
		
		document.getElementById("real_video_failure").src = failureObjectList[object] + ".mp4";
//		document.getElementById("real_plot_failure").src = failureObjectList[object] + ".html";
		document.getElementById("failure-text").textContent= failureTextList[object];
	}
	
	function switchSimVideo() {
		var object = document.simObjectForm.switch.options[document.simObjectForm.switch.selectedIndex].value;
		var videoList = Array();
		
		document.getElementById("sim_video").src = simObjectList[object] + ".mp4";
		document.getElementById("sim_plot").src = simObjectList[object] + ".html";
//		document.getElementById("failure-text").textContent= failureTextList[object];
	}
	  
	 
	 
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="./index.html">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Align Before You Act: Reasoning-Action Alignment
via Runtime Steering for Vision-Language-Action Models</h1>
          <!-- <h1 class="title is-5 publication-title">CoRL 2023 (Oral Presentation)</h1> -->
		  <div class="is-size-5 publication-authors">
			<span class="author-block">Anonymous Authors</span>
			<!-- <span class="author-block">
				<a href="https://yilin-wu98.github.io/">Yilin Wu</a><sup>1,2,*</sup>,</span>
				<span class="author-block">
				<a href="https://thomasrantian.github.io/">Anqi Li</a><sup>2</sup>,</span>
				<span class="author-block">
				<a href="https://gokul.dev/">Tucker Hermans</a><sup>2</sup>,</span>
				<span class="author-block">
				<a href="https://gokul.dev/">Fabio Ramos</a><sup>2</sup>,</span>
				<span class="author-block">
				<a href="https://www.cs.cmu.edu/~abajcsy/">Andrea Bajcsy</a><sup>1,&dagger;</sup>
				</span>
				<span class="author-block">
				<a href="https://www.cs.cmu.edu/~abajcsy/">Claudia D'Arpino</a><sup>2,&dagger;</sup>
				</span> -->
			
          </div>

          <!-- <div class="is-size-10 publication-authors">
            <span class="author-block"><sup>1</sup>Carnegie Mellon University   </span>
            <span class="author-block"><sup>2</sup>Nvidia</span>
			<span class="author-block"><sup>*</sup>Work done during an internship at Nvidia</span>
			<span class="author-block"><sup>&dagger;</sup>Equal Advising</span>
          </div> -->

		  <div class="column has-text-centered">
            <div class="publication-links">
				<span class="link-block">
					<a href=""
						class="external-link button is-normal is-rounded is-dark">
						<span class="icon">
							<i class="ai ai-arxiv"></i>
						</span>
						<span>Appendix</span>
					</a>
					</span>
				<span class="link-block">
				<a href=""
					class="external-link button is-normal is-rounded is-dark">
					<span class="icon">
						<i class="fab fa-github"></i>
					</span>
					<span>Code (Coming soon)</span>
					</a>
				</span>
            </div>

        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <video id="teaser" autoplay muted loop playsinline width="70%">
        <source src="./static/videos/front_video_v2.mp4"
                type="video/mp4">
      </video>
		<br>
      <h2 class="subtitle has-text-centered">
        Our method <span class="dnerf">FOREWARN</span> proposes a VLM-in-the-loop policy steering system to improve multi-modal generative policy's performance during deployment without retraining. 
      </h2>
    </div>
  </div>
</section> -->

<!-- <section class="hero is-light is-small">
	<div class="hero-body">
	  <div class="container">
		<div id="results-carousel" class="carousel results-carousel">
		  
		  
		  
		  
			
			
		<div  class="slider" tabindex="0">
<div class="slider-container" style="opacity: 1;  transition: 600ms; ">

			</div></div><div class="slider-item is-current" data-slider-index="0" style="width: 300px;"><div class="item-5">
				<video poster="" id="1" controls="" muted="" loop="" autoplay playsinline="" height="50%">
					<source src="./static/videos/real_world_results/cup_handle/base_policy.mp4" type="video/mp4">
				</video>
				<div class="video-overlay">
					<p>
					  Task Description: "serve the cup of water to the guest"<br>
					  Implied Behavior: grasp the cup by the handle 
					  Unsteered Policy: Diffusion Policy (Base Policy)
					</p>
					<p style="color: red">Failure</p>
				</div>
			</div></div><div class="slider-item is-slide-next" data-slider-index="1" style="width: 300px;" ><div class="item-6">
				<video poster="" id="2" controls="" muted="" loop="" autoplay playsinline="" height="50%">
					<source src="./static/videos/real_world_results/cup_handle/forewarn.mp4" type="video/mp4">
				</video>
				<div class="video-overlay">
					<p>
						Task Description: "serve the cup of water to the guest."<br>
						Implied Behavior: grasp the cup by the handle <br>
						Steered Policy: FOREWARN (Ours)
					</p>
					<p style="color: green">Success</p>
				</div>
			</div></div><div class="is-slide-previous" data-slider-index="2" style="width: 300px;" >
				<div class="item-1">
			<video poster="" id="3" controls="" muted="" loop=""  autoplay playsinline="" height="50%">
				<source src="./static/videos/real_world_results/cup_rim/base_policy.mp4" type="video/mp4">
			</video>
			<div class="video-overlay">
				<p>
					Task Description: "The handle is covered with oil."<br>
					Implied Behavior: grasp the cup by the rim <br>
					Unsteered Policy: Diffusion Policy (Base Policy)
				  </p>
				  <p style="color: red">Failure</p>
			</div>
		  </div></div><div class="slider-item" data-slider-index="3" data-cloned="true" style="width: 300px;"><div class="item-2">
			  <video poster="" id="4" controls="" muted="" loop="" autoplay playsinline="" height="50%">
				  <source src="./static/videos/real_world_results/cup_rim/forewarn.mp4" type="video/mp4">
			  </video>
			  <div class="video-overlay">
				  <p>
					Task Description: "The handle is covered with oil."<br>
					Implied Behavior: grasp the cup by the rim <br>
					Steered Policy: FOREWARN (Ours)
					</p>
				  </p>
				  <p style="color: green">Success</p>
			  </div>
		  </div></div><div class="slider-item" data-slider-index="4" data-cloned="true" style="width: 300px;" ><div class="item-3">
			  <video poster="" id="5" controls="" muted="" loop="" autoplay playsinline="" height="50%">
				  <source src="./static/videos/real_world_results/bag_edge/base_policy.mp4" type="video/mp4">
			  </video>
			  <div class="video-overlay">
				  <p>
					Task Description: "minimize the contact region to avoid crushing contents inside"<br>
					Implied Behavior: grasp the bag via the edge<br>
					Unsteered Policy: Diffusion Policy (Base Policy)
				  </p>
				  <p style="color: red">Failure</p>
			  </div>
		  
		  </div></div><div class="slider-item" data-slider-index="5" data-cloned="true" style="width: 300px;" ><div class="item-4">
			  <video poster="" id="6" controls="" muted="" loop="" autoplay playsinline="" height="50%">
				  <source src="./static/videos/real_world_results/bag_edge/forewarn.mp4" type="video/mp4">
			  </video>
			  <div class="video-overlay">
				  <p>
					Task Description: "minimize the contact region to avoid crushing contents inside"<br>
					Implied Behavior: grasp the bag via the edge<br>
					Steered Policy: FOREWARN (Ours)
				  </p>
				  <p style="color: green">Success</p>
			  </div>
		  </div></div><div class="slider-item" data-slider-index="6" data-cloned="true" style="width: 300px;"><div class="item-5">
			  <video poster="" id="7" controls="" muted="" loop="" autoplay playsinline="" height="50%">
				  <source src="./static/videos/real_world_results/bag_middle/base_policy.mp4" type="video/mp4">
			  </video>
			  <div class="video-overlay">
				  <p>
					Task Description: "maximize the stability without dropping the bag"<br>
					Implied Behavior: grasp the bag via the middle part<br>
					Unsteered Policy: Diffusion Policy (Base Policy)
				  </p>
				  <p style="color: red">Failure</p>
				  
			  </div>
			</div></div><div class="slider-item" data-slider-index="6" data-cloned="true" style="width: 300px;"><div class="item-5">
				<video poster="" id="7" controls="" muted="" loop="" autoplay playsinline="" height="50%">
					<source src="./static/videos/real_world_results/bag_middle/forewarn.mp4" type="video/mp4">
				</video>
				<div class="video-overlay">
					<p>
					  Task Description: "maximize the stability without dropping the bag"<br>
					  Implied Behavior: grasp the bag via the middle part<br>
					  Steered Policy: FOREWARN (Ours)
					</p>
					<p style="color: green">Success</p>
					
				</div>
		  </div></div></div>
 <div class="slider-navigation-previous">
	<svg viewBox="0 0 50 80" xml:space="preserve">
<polyline fill="currentColor" stroke-width=".5em" stroke-linecap="round" stroke-linejoin="round" points="45.63,75.8 0.375,38.087 45.63,0.375 ">

</polyline>
</svg>
</div>
<div class="slider-navigation-next"><svg viewBox="0 0 50 80" xml:space="preserve">
<polyline fill="currentColor" stroke-width=".5em" stroke-linecap="round" stroke-linejoin="round" points="0.375,0.375 45.63,38.087 0.375,75.8 ">

</polyline>
</svg>
</div>
<div class="slider-pagination">
	<div class="slider-page" data-index="0">

	</div>
	<div class="slider-page" data-index="1">

</div>
<div class="slider-page" data-index="2"></div><div class="slider-page" data-index="3">

</div>
<div class="slider-page" data-index="4">

</div>
<div class="slider-page is-active" data-index="5">

</div> 
</div></div></div>
	  </div>
	</div>
  </section> -->


		<!-- <div class="slider" tabindex="0">
			<div class="slider-container" style="opacity: 1; width: 7809px; transition: 300ms; transform: translate3d(-3715px, 0px, 0px);">
				<div class="slider-item" data-slider-index="-4" data-cloned="true" style="width: 411px;">
					<div class="item-3">
	
          <video poster="" id="steve" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/real_world_results/cup_handle/forewarn.mp4"
                    type="video/mp4">
					
          </video>
		  <div class="video-overlay">
			<p>
			  Task: "place the carrot on yellow plate"<br>
			  Scenario: object distractors <br>
			  Policy: Octo-Base <b>with BYOVLA</b>
			</p>
			<p style="color: green">Success</p>
		</div>
        </div>
		</div>

		
				<div class="slider-item" data-slider-index="-3" data-cloned="true" style="width: 411px;">
					<div class="item-4">
	
          <video poster="" id="steve" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/real_world_results/cup_handle/forewarn.mp4"
                    type="video/mp4">
					
          </video>
		  <div class="video-overlay">
			<p>
			  Task: "place the carrot on yellow plate"<br>
			  Scenario: object distractors <br>
			  Policy: Octo-Base <b>with BYOVLA</b>
			</p>
			<p style="color: green">Success</p>
		</div>
        </div>
		</div>
	
		
				<div class="slider-item" data-slider-index="-2" data-cloned="true" style="width: 411px;">
					<div class="item-5">
	
          <video poster="" id="steve" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/real_world_results/cup_handle/forewarn.mp4"
                    type="video/mp4">
					
          </video>
		  <div class="video-overlay">
			<p>
			  Task: "place the carrot on yellow plate"<br>
			  Scenario: object distractors <br>
			  Policy: Octo-Base <b>with BYOVLA</b>
			</p>
			<p style="color: green">Success</p>
		</div>
        </div>
		</div>
		
		
				<div class="slider-item" data-slider-index="-1" data-cloned="true" style="width: 411px;">
					<div class="item-6">
	
          <video poster="" id="steve" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/real_world_results/cup_handle/forewarn.mp4"
                    type="video/mp4">
					
          </video>
		  <div class="video-overlay">
			<p>
			  Task: "place the carrot on yellow plate"<br>
			  Scenario: object distractors <br>
			  Policy: Octo-Base <b>with BYOVLA</b>
			</p>
			<p style="color: green">Success</p>
		</div>
        </div>
		</div>
		</div>
		</div> -->
         <!-- <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/real_world_results/cup_rim/forewarn.mp4"
                    type="video/mp4">
          </video>
        </div> -->
		<!-- <div class="item item-chair-tp">
			<video poster="" id="chair-tp" autoplay controls muted loop playsinline height="50%">
			  <source src="./static/videos/real_world_results/cup_rim/forewarn.mp4"
					  type="video/mp4">
			</video>
		  </div> -->
        <!--<div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/real_world_results/bag_edge/forewarn.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/real_world_results/bag_middle/forewarn.mp4"
                    type="video/mp4">
          </video>
        </div> -->
    
        
      <!-- </div>
    </div>
  </div> -->


<!-- <section class="section">
	<div class="container is-fluid">
  
	  <div class="columns is-centered">
  
		
		<div class="column">
		  <div class="content">
			<h2 class="title is-3">Visual Effects</h2>
			<p>
			  Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
			  would be impossible without nerfies since it would require going through a wall.
			</p>
			<video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
			  <source src="./static/videos/real_world_results/cup_handle/vlmact.mp4"
					  type="video/mp4">
			</video>
		  </div>
		</div>
	
  

		<div class="column">
		  <h2 class="title is-3">Matting</h2>
		  <div class="columns is-centered">
			<div class="column content">
			  <p>
				As a byproduct of our method, we can also solve the matting problem by ignoring
				samples that fall outside of a bounding box during rendering.
			  </p>
			  <video id="matting-video" controls playsinline height="100%">
				<source src="./static/videos/real_world_results/cup_handle/vlmact.mp4"
						type="video/mp4">
			  </video>
			</div>
  
		  </div>
		</div>
		<div class="column">
			<h2 class="title is-3">Matting</h2>
			<div class="columns is-centered">
			  <div class="column content">
				<p>
				  As a byproduct of our method, we can also solve the matting problem by ignoring
				  samples that fall outside of a bounding box during rendering.
				</p>
				<video id="matting-video" controls playsinline height="100%">
				  <source src="./static/videos/real_world_results/cup_handle/vlmact.mp4"
						  type="video/mp4">
				</video>
			  </div>
	
			</div>
		  </div>
		  <div class="column">
			<h2 class="title is-3">Matting</h2>
			<div class="columns is-centered">
			  <div class="column content">
				<p>
				  As a byproduct of our method, we can also solve the matting problem by ignoring
				  samples that fall outside of a bounding box during rendering.
				</p>
				<video id="matting-video" controls playsinline height="100%">
				  <source src="./static/videos/real_world_results/cup_handle/vlmact.mp4"
						  type="video/mp4">
				</video>
			  </div>
	
			</div>
		  </div>
		  <div class="column">
			<h2 class="title is-3">Matting</h2>
			<div class="columns is-centered">
			  <div class="column content">
				<p>
				  As a byproduct of our method, we can also solve the matting problem by ignoring
				  samples that fall outside of a bounding box during rendering.
				</p>

				<video id="matting-video" controls playsinline height="100%">
					
				  <source src="./static/videos/real_world_results/cup_handle/vlmact.mp4"
						  type="video/mp4">
				</video>
			  </div>
	
			</div>
		  </div>
	  </div>

 
</div>

	
  
  
  </section>
   -->
  
   <!--  -->
  

<!-- <section class="section">
  <div class="container is-max-desktop">
     Abstract.
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          	<p>
				While generative robot policies have demonstrated significant potential in learning complex, multimodal behaviors from demonstrations, they still exhibit diverse failures at deployment-time. Policy steering offers an elegant solution to reducing the chance of failure by using an external verifier to select from low-level actions proposed by an imperfect generative policy. Here, one might hope to use a Vision Language Model (VLM) as a verifier, leveraging its open-world reasoning capabilities. However, off-the-shelf VLMs struggle to understand the consequences of low-level robot actions as they are represented fundamentally differently than the text and images the VLM was trained on. In response, we propose FOREWARN, a novel framework to unlock the potential of VLMs as open-vocabulary verifiers for runtime policy steering. Our key idea is to decouple the VLM’s burden of predicting action outcomes (foresight) from evaluation (forethought). For foresight, we leverage a latent world model to imagine future latent states given diverse low-level action plans. For forethought, we align the VLM with these predicted latent states to reason about the consequences of actions in its native representation—natural language—and effectively filter proposed plans. We validate our framework across diverse robotic manipulation tasks, demonstrating its ability to bridge representational gaps and provide robust, generalizable policy. </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
     Animation. 
    <div class="columns is-centered">
      <div class="column is-full-width">
	  	<h2 class="title is-3"><span class="dnerf"> FOREWARN</span></h2>
		<h3 class="title is-4"> <span class="dnerf">Filtering Options via REpresenting World-model Action Rollouts via Narration </span> </h3>
	  	<br>
		<img src="static/figures/method.png" alt="Method Figure">
		<br><br>
		<p>
			We present our method FOREWARN, an VLM-in-the-loop policy steering algorithm for multi-modal generative robot policies.
Our key idea is to decouple the VLM’s burden of predicting action outcomes from evaluation. By predicting action outcomes
with a pre-trained latent dynamics model and aligning a VLM to reason about these latent states in text, FOREWARN can
select action plans at runtime that are most appropriate for new task contexts and user needs.
		</p>
	</div>
		
	</div>
  </div>
</section>

<section class="section">
	<div class="container is-max-desktop">
	   Animation. 
	  <div class="columns is-centered">
		<div class="column is-full-width">
			<h2 class="title is-3"> Training Pipeline</h2>
			<br>
		  <img src="static/figures/architecture_figure.png" alt="Training Pipeline">
		  <br><br>
		  <p>
			On the left, a world model is pretrained to learn good latent embeddings of the
			dynamics conditioned on the observations and actions. On the right, the sequence of learned latent embeddings is
			projected through a linear layer to the text embedding space, similar to the original vision token processing in the Llama-3.2
			Model. The projection layer and Llama model are finetuned together using LoRA, but the world model remains frozen. We finetune the VLM to align the latent embedding with underlying textual representation so we design a visual question answering task to ask VLM to generate behavior narrations that capture nuanced details.
		  </p>
	  </div>
		  
	  </div>
	</div>
  </section>

  


<section class="section" id="real-world-results">
	<div class="container is-fluid">
	   Section Title 
	 <div class="container is-max-desktop">
	  <div class="columns">
		<div class="column is-four-fifths">
		  <h2 class="title is-3">Real World Results</h2>
		</div>
		</div>
	  </div>
	  <div class="container is-max-desktop">
	  <div class ="columns ">
		<div class="column is-full-width" style="margin-top: 20px;">
			<h3 class="title is-4">Qualitative Results for Behavior Narration</h3>
			<p>We demonstrate real-world deployments of our system across various tasks.</p> 
			 <p><span style="font-weight: bold;font-size: 20px"> Baselines </span><br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#FF9300"> FOREWARN </span> : our proposed method using the world model for predicting the latent states of the future and finetuned VLM for generating behavior narrations.<br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#a54c00"> FOREWARN-Oracle </span>: an upper-bound on our approach's
				performance assuming access to ground-truth future observations (instead of relying on
				the latent dynamics to predict future outcomes).<br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#26A6D5">VLM-Act </span>: directly fine-tuning the original Llama-3.2-11B-Vision-Instruct model to generate behavior narrations end-to-end from current observation and an action plan(represented as text), without explicitly predicting outcomes with a world model. <br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#0d79ca">VLM-Img </span>: using a GPT-4o to generate behavior narrations in a zero-shot manner from the predicted visual observations from the world model.<br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#233c80"> VLM-Img-Oracle </span>: an upper-bound on the performance of VLM-Img, assuming access to ground-truth visual observations.<br>
				<br>
				On the left are videos of the ground-truth observations. On the right are the prompt used for querying and the generated behavior narrations. Only
				<span id="text" style="font-weight: bold;font-size: 15px;color:#FF9300"> FOREWARN </span> and
						   <span id="text" style="font-weight: bold;font-size: 15px;color:#a54c00"> FOREWARN-Oracle </span>  consistently produce accurate outcome narrations, effectively capturing nuanced motion details. In contrast, the baselines frequently hallucinate or fail to
				capture critical contact details between the gripper and objects.
				  For instance, in the Bag task, <span id="text" style="font-weight: bold;font-size: 15px;color:#26A6D5">VLM-Act </span>, 
				<span id="text" style="font-weight: bold;font-size: 15px;color:#0d79ca"> VLM-Img </span>, 
				and <span id="text" style="font-weight: bold;font-size: 15px;color:#233c80"> VLM-Img-Oracle </span>  all hallucinate that the robot is grasping the edge of the
				bag, whereas it is actually grasping the middle.
			</p>
		
		 </div>
		</div>
		</div>
		 <section class="section"> 
			<div class="container is-max-desktop">
			  Two columns 
			   Right column (video) - smaller width 
			   <div class ="columns is-centered has-text-centered">
				<div class="column is-four-fifths">
					<h4 class="title is-5">Cup Task</h4>

					
				 </div>
				</div>
			   <div class="columns">
				
				<div class="column is-one-third has-text-centered">
				<video
				style="width: 60%;"
				autoplay
				loop
				muted
				playsinlines
				controls
			  >
				<source src="static/videos/cup_wrist_bn.mp4" type="video/mp4">
				
			  </video>
			</div>
		

				
				
				 
				<div class="column is-two-thirds has-text-centered">
					<img
					  src="static/figures/cup_wrist_bn.png"
					  alt="Left image"
					  style="width: 85%;"
					/>
			
				</div>
			</div>
			</div>
			<div class="container is-max-desktop">
				
				 <div class ="columns is-centered has-text-centered">
				  <div class="column is-four-fifths">
					  <h4 class="title is-5">Bag Task</h4>
  
					 
			
				   </div>
				  </div>
				 <div class="columns">
				  
				  <div class="column is-one-third has-text-centered">
				  <video
				  style="width: 60%;"
				  autoplay
				  loop
				  muted
				  playsinlines
				  controls
				>
				  <source src="static/videos/bag_wrist_bn.mp4" type="video/mp4">
				 
				</video>
			  </div>
		  
  
				  
				  
					
				  <div class="column is-two-thirds has-text-centered">
					  <img
						src="static/figures/bag_wrist_bn.png"
						alt="Left image"
						style="width: 85%;"
					  />
			  
				  </div>
			  </div>
			  </div>
		
		  
		<div class="container is-max-desktop">
			
		<div class ="columns">
			<div class="column is-full-width" style="margin-top: 100px;">
				<h3 class="title is-4">Quantitative Results for Behavior Narration</h3>
				<div class="container is-max-desktop">
					<p>We conduct experiments to show the alignment between predicted behavior narrations from different methods and ground-truth narrations. 
						<span id="text" style="font-weight: bold;font-size: 15px;color:#FF9300"> FOREWARN </span>
						outperforms all baselines across both tasks and achieves performance comparable to
						 <span id="text" style="font-weight: bold;font-size: 15px;color:#a54c00"> FOREWARN-Oracle </span> , 
						 which has access to ground-truth action outcomes and represents the upper bound for our approach. 
		</p>
	  <img src="static/figures/behavior_narration.png" alt="behavior narration" style="width: 100%;"> 
	</div>
				
			 </div>
			</div>
			</div>
		<div class="container is-max-desktop">
	  <div class ="columns">
		<div class="column is-full-width" style="margin-top: 100px;">
			<h3 class="title is-4">Qualitative Results for Policy Steering</h3>
			<p><span style="font-weight: bold;font-size: 20px"> Baselines </span><br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#FF9300"> FOREWARN </span> : our proposed method that (1)predicts the action outcomes with the world model in latent space; (2)generates behavior narrations with finetuned VLM from latent states of the future; (3)selects the best action plan using the same VLM based on the task description and narrations.<br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#26A6D5">VLM-Act </span>: directly finetuning the VLM to generate behavior narrations from observations and the action plans without explicit world model while keeping (3) same as our method. <br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#724F8F">VLM-DynLat-Category </span>: keeping (1) similar to our method while directly finetuning VLM to generate a set of indices for valid action plans based on task descriptions and predicted latent states of the future, combining (2) and (3) together.<br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#CE5C7C">Classifier-Dyn-Latent </span>: similar to <span id="text" style="font-weight: bold;font-size: 15px;color:#724F8F">VLM-DynLat-Category </span> but using a learned classifier instead a VLM to predict success/failure for each plan and randomly select from the successful plans.<br>
				
				<br>
				Our results demonstrate that <span id="text" style="font-weight: bold;font-size: 15px;color:#FF9300"> FOREWARN </span>  can effectively steer the policy towards safe and aligned behavior modes by leverging the VLM as an interpreter and evaluator of predicted latent action outcomes. It outperforms <span id="text" style="font-weight: bold;font-size: 15px;color:#26A6D5">VLM-Act </span> in all tasks and <span id="text" style="font-weight: bold;font-size: 15px;color:#CE5C7C">Classifier-Dyn-Latent </span> as well as <span id="text" style="font-weight: bold;font-size: 15px;color:#724F8F">VLM-DynLat-Category </span> in novel task descriptions (not seen during training). </p>
		
		 <p></p>
		 </div>
		</div>
		</div>
		<div calss ="columns is-centered has-text-centered">
			<div class="column is-one-fifths">
			
				<div class="container is-fluid" style="text-align: center;">
	  <img src="static/figures/cup_task.png" alt="Task Scenario 1" style="width: 80%;">
	</div>
			
			 </div>
			</div>

	  <div class="columns">
		
		
		<div class="column is-one-fifth has-text-centered">
			<span id="text" style="font-weight: bold;font-size: 15px;color:#000000"> Base Policy </span>

		  <video
			autoplay
			loop
			muted
			playsinline
			controls
			width="100%"
			style="border-radius: 10px;">
			<source src="static/videos/real_world_results/cup_handle/base_policy.mp4" type="video/mp4">
		  </video>
		</div>
		

		<div class="column is-one-fifth has-text-centered">
			<span id="text" style="font-weight: bold;font-size: 15px;color:#FF9300"> FOREWARN </span>

		  <video
			autoplay
			loop
			muted
			playsinline
			controls
			width="100%"
			style="border-radius: 10px;">
			<source src="static/videos/real_world_results/cup_handle/forewarn.mp4" type="video/mp4">
		  </video>
		</div>
		
	
		<div class="column is-one-fifth has-text-centered">
			<span id="text" style="font-weight: bold;font-size: 15px;color:#26A6D5">VLM-Act </span>

		  <video
			autoplay
			loop
			muted
			playsinline
			controls
			width="100%"
			style="border-radius: 10px;">
			<source src="static/videos/real_world_results/cup_handle/vlmact.mp4" type="video/mp4">
		  </video>
		</div>
		
		
		<div class="column is-one-fifth has-text-centered">
			<span id="text" style="font-weight: bold;font-size: 15px;color:#724F8F">VLM-DynLat-Category </span>

		  <video
			autoplay
			loop
			muted
			playsinline
			controls
			width="100%"
			style="border-radius: 10px;">
			<source src="static/videos/real_world_results/cup_handle/vlm_dynlat_cat.mp4" type="video/mp4">
		  </video>
		</div>
		
		
		<div class="column is-one-fifth has-text-centered">
			<span id="text" style="font-weight: bold;font-size: 15px;color:#CE5C7C">Classifier-Dyn-Latent </span>

		  <video
			autoplay
			loop
			muted
			playsinline
			controls
			width="100%"
			style="border-radius: 10px;">
			<source src="static/videos/real_world_results/cup_handle/classifier_dyn_lat.mp4" type="video/mp4">
		  </video>
		</div>
		
	  </div>
	  
  

	<div calss ="columns is-centered has-text-centered">
		<div class="column is-one-fifths">
	
			<div class="container is-fluid" style="text-align: center;">
  <img src="static/figures/bag_task.png" alt="Task Scenario 2" style="width: 80%;">
</div>
	
		
		 </div>
		</div>
  <div class="columns">
	

	<div class="column is-one-fifth has-text-centered">
		<span id="text" style="font-weight: bold;font-size: 15px;color:#000000"> Base Policy </span>

	  <video
		autoplay
		loop
		muted
		playsinline
		controls
		width="100%"
		style="border-radius: 10px;">
		<source src="static/videos/real_world_results/bag_edge/base_policy.mp4" type="video/mp4">
	  </video>
	</div>
	
	
	<div class="column is-one-fifth has-text-centered">
		<span id="text" style="font-weight: bold;font-size: 15px;color:#FF9300"> FOREWARN </span>

	  <video
		autoplay
		loop
		muted
		playsinline
		controls
		width="100%"
		style="border-radius: 10px;">
		<source src="static/videos/real_world_results/bag_edge/forewarn.mp4" type="video/mp4">
	  </video>
	</div>
	
	
	<div class="column is-one-fifth has-text-centered">
		<span id="text" style="font-weight: bold;font-size: 15px;color:#26A6D5">VLM-Act </span>

	  <video
		autoplay
		loop
		muted
		playsinline
		controls
		width="100%"
		style="border-radius: 10px;">
		<source src="static/videos/real_world_results/bag_edge/vlmact.mp4" type="video/mp4">
	  </video>
	</div>
	
	
	<div class="column is-one-fifth has-text-centered">
		<span id="text" style="font-weight: bold;font-size: 15px;color:#724F8F">VLM-DynLat-Category </span>

	  <video
		autoplay
		loop
		muted
		playsinline
		controls
		width="100%"
		style="border-radius: 10px;">
		<source src="static/videos/real_world_results/bag_edge/vlm_dynlat_cat.mp4" type="video/mp4">
	  </video>
	</div>
	
	
	<div class="column is-one-fifth has-text-centered">
		<span id="text" style="font-weight: bold;font-size: 15px;color:#CE5C7C">Classifier-Dyn-Latent </span>

	  <video
		autoplay
		loop
		muted
		playsinline
		controls
		width="100%"
		style="border-radius: 10px;">
		<source src="static/videos/real_world_results/bag_edge/classifier_dyn_lat.mp4" type="video/mp4">
	  </video>
	</div>
	
  </div>

  <div calss ="columns is-centered has-text-centered">
	<div class="column is-one-fifths">
		
		<div class="container is-fluid" style="text-align: center;">
<img src="static/figures/cup_new.png" alt="Task Scenario 3" style="width: 80%;"> 
</div>
		

	 </div>
	</div>
<div class="columns">


<div class="column is-one-fifth has-text-centered">
	<span id="text" style="font-weight: bold;font-size: 15px;color:#000000"> Base Policy </span>

  <video
	autoplay
	loop
	muted
	playsinline
	controls
	width="100%"
	style="border-radius: 10px;">
	<source src="static/videos/real_world_results/cup_rim/base_policy.mp4" type="video/mp4">
  </video>
</div>


<div class="column is-one-fifth has-text-centered">
	<span id="text" style="font-weight: bold;font-size: 15px;color:#FF9300"> FOREWARN </span>

  <video
	autoplay
	loop
	muted
	playsinline
	controls
	width="100%"
	style="border-radius: 10px;">
	<source src="static/videos/real_world_results/cup_rim/forewarn.mp4" type="video/mp4">
  </video>
</div>


<div class="column is-one-fifth has-text-centered">
	<span id="text" style="font-weight: bold;font-size: 15px;color:#26A6D5">VLM-Act </span>

  <video
	autoplay
	loop
	muted
	playsinline
	controls
	width="100%"
	style="border-radius: 10px;">
	<source src="static/videos/real_world_results/cup_rim/vlmact.mp4" type="video/mp4">
  </video>
</div>


<div class="column is-one-fifth has-text-centered">
	<span id="text" style="font-weight: bold;font-size: 15px;color:#724F8F">VLM-DynLat-Category </span>

  <video
	autoplay
	loop
	muted
	playsinline
	controls
	width="100%"
	style="border-radius: 10px;">
	<source src="static/videos/real_world_results/cup_rim/vlm_dynlat_cat.mp4" type="video/mp4">
  </video>
</div>


<div class="column is-one-fifth has-text-centered">
	<span id="text" style="font-weight: bold;font-size: 15px;color:#CE5C7C">Classifier-Dyn-Latent </span>

  <video
	autoplay
	loop
	muted
	playsinline
	controls
	width="100%"
	style="border-radius: 10px;">
	<source src="static/videos/real_world_results/cup_rim/classifier_dyn_lat.mp4" type="video/mp4">
  </video>
</div>

</div>
<div calss ="columns is-centered has-text-centered">
	<div class="column is-one-fifths">
		
		<div class="container is-fluid" style="text-align: center;">
<img src="static/figures/bag_new.png" alt="Task Scenario 4" style="width: 80%;">
</div>

	 </div>
	</div>
<div class="columns">


<div class="column is-one-fifth has-text-centered">
	<span id="text" style="font-weight: bold;font-size: 15px;color:#000000"> Base Policy </span>

  <video
	autoplay
	loop
	muted
	playsinline
	controls
	width="100%"
	style="border-radius: 10px;">
	<source src="static/videos/real_world_results/bag_middle/base_policy.mp4" type="video/mp4">
  </video>
</div>


<div class="column is-one-fifth has-text-centered">
	<span id="text" style="font-weight: bold;font-size: 15px;color:#FF9300"> FOREWARN </span>

  <video
	autoplay
	loop
	muted
	playsinline
	controls
	width="100%"
	style="border-radius: 10px;">
	<source src="static/videos/real_world_results/bag_middle/forewarn.mp4" type="video/mp4">
  </video>
</div>


<div class="column is-one-fifth has-text-centered">
	<span id="text" style="font-weight: bold;font-size: 15px;color:#26A6D5">VLM-Act </span>

  <video
	autoplay
	loop
	muted
	playsinline
	controls
	width="100%"
	style="border-radius: 10px;">
	<source src="static/videos/real_world_results/bag_middle/vlmact.mp4" type="video/mp4">
  </video>
</div>


<div class="column is-one-fifth has-text-centered">
	<span id="text" style="font-weight: bold;font-size: 15px;color:#724F8F">VLM-DynLat-Category </span>

  <video
	autoplay
	loop
	muted
	playsinline
	controls
	width="100%"
	style="border-radius: 10px;">
	<source src="static/videos/real_world_results/bag_middle/vlm_dynlat_cat.mp4" type="video/mp4">
  </video>
</div>


<div class="column is-one-fifth has-text-centered">
	<span id="text" style="font-weight: bold;font-size: 15px;color:#CE5C7C">Classifier-Dyn-Latent </span>

  <video
	autoplay
	loop
	muted
	playsinline
	controls
	width="100%"
	style="border-radius: 10px;">
	<source src="static/videos/real_world_results/bag_middle/classifier_dyn_lat.mp4" type="video/mp4">
  </video>
</div>

</div>
</div>
<div class="container is-max-desktop">
	<div class="columns">
	<div class="column is-four-fifths" style="margin-top: 100px;">
		<h3 class="title is-4">Quantitative Results for Policy Steering</h3>
	 </div>
	</div>
	
	<div style="text-align: center;">
		<video 
		  style="width: 90%;" 
		  controls
		  autoplay 
		  loop 
		  muted 
		  playsinline
		>
		  <source src="static/videos/policy_steering_quantitativre.mp4" type="video/mp4">
		  
		  
		</video>
	  </div>
	</div>
	
  </section>-->
  
  <!--	Real Robot Success-->
<!-- <section class="section">
	<div class="columns is-centered">
		<h2 class="title is-3"><span class="dnerf"> Real Robot Results </span></h2>
	</div>
	<br>
	
	
	<div class="columns is-centered">
		<h3 class="title is-4"> Successes </h3>
	</div>
	<br>
	
	<div class="columns is-centered">
		<p>
			Object: &nbsp
	  </p>
	  <form method="" action="" name="successObjectForm">
		<select size="1" name="switch" onchange="switchSuccessVideo();">
			<option value="1">Blue Cup</option>
			<option value="2">Box</option>
			<option value="9">Wood Block</option>
			<option value="4">Milk Carton</option>
			<option value="3">Hook</option>
			<option value="7">Toy Block</option>
			<option value="5">Red Bottle</option>
			<option value="8">Toy Bridge</option>
			<option value="6">Red Mug</option>
			<option value="0">Black Mug</option>
		</select>
		</form>
	</div>
</section> -->

	
<!--	success video-->
<!-- <div class="container is-centered is-max-desktop">
	<video id="real_video_success"
		 controls
		 muted
		 preload
		 playsinline
		 width="100%">
		<source src="./static/demos/success/blue-cup.mp4"
				type="video/mp4">
	</video> -->
<!--	<embed type="text/html" src="./static/demos/success/blue-cup.html" width="35%" height="500" id="real_plot_success">-->
<!-- </div>
<br> 

	
real robot failures
<section class="section">
	<div class="container is-max-desktop">
	<div class="columns">
		<h3 class="title is-4"> Failure Modes </h3>
	</div>
	<br>
	
	<div class="columns is-centered is-four-fifths">
		<span>
			<b> Interactive Visuliazation: </b>&nbsp; Drag the slider to visualize different failure modes.
		</span>
	</div>
	<br>
	</div>

	
	 <div class="columns is-centered">
	<p>
	  Failure Case: &nbsp; </p>
	<form method="" action="" name="failureObjectForm">
	<select size="1" name="switch" onchange="switchFailureVideo();">
		<option value="0">World Model Failure</option>
		<option value="1">VLM Behavior Generation Failure</option>
		<option value="2">VLM Reasoning Failure</option>
	</select>
	</form>
	</div>
	<br>
	
	<div class="container is-max-desktop has-text-centered">
		<span id="failure-text" style="color:#5E5E5E"> In this example, the actual execution of the action plan knocks the cup down on the table while the world model mistakenly imagines the robot successfully picks up the cup from the table via the handle. </span>
	</div>
</section>


 <div class="container is-centered is-max-desktop">
	<video id="real_video_failure"
		 controls
		 muted
		 preload
		 playsinline
		 width="100%">
		<source src="./static/videos/failure_world_model.mp4"
				type="video/mp4">
	</video> 
<embed type="text/html" src="./static/demos/failure/failure-1.html" width="35%" height="500" id="real_plot_failure">
</div>
<br> <br> --> 

<!-- <section class="section">
	<div class="columns is-centered">
		<h2 class="title is-3"><span class="dnerf"> Failure Modes &nbsp; </span> with Interactive Visualizations&nbsp; </h2>
	</div>
	<br>
	
	<div class="container is-max-desktop has-text-centered">
		<span>
			<b> Interactive Visuliazation: </b>&nbsp; Drag the slider to visualize different timesteps. 
			Click on the legends <strong>on the plot</strong> to show/hide elements.
		</span>
	</div>
  	<br> -->
	
<!--
	<div class="columns is-centered">
		<h3 class="title is-4"> Notations </h3>
	</div>
-->
	
	<!-- <div class="container is-max-desktop">
	  <img src="static/figures/plotly_notations.png" alt="Legend notations">
	</div>
	<br> -->
<!-- 	
	<div class="columns is-centered">
	<p>
	  Object: &nbsp; </p>
	<form method="" action="" name="simObjectForm">
	<select size="1" name="switch" onchange="switchSimVideo();">
		<option value="0">Tape</option>
		<option value="1">Cup</option>
		<option value="2">Cube</option>
		<option value="3">Pill Bottle</option>
		<option value="4">Teapot</option>
	</select>
	</form>
	</div>
	 -->
	
<!-- </section>

<div class="is-centered columns">
	<video id="sim_video"
		 controls
		 muted
		 preload
		 playsinline
		 height="640px"
		 width="55%">
		<source src="./static/demos/sim/tape.mp4"
				type="video/mp4">
	</video>
	<embed type="text/html" src="./static/demos/sim/tape.html" width="40%" height="640px" id="sim_plot">
</div>
	
<br> <br> -->


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{wu2025forewarn,
		title={From Foresight to Forethought: VLM-In-the-Loop Policy Steering via Latent Alignment}, 
		author={Yilin Wu and Ran Tian and Gokul Swamy and Andrea Bajcsy},
		year={2025},
		eprint={2502.01828},
		archivePrefix={arXiv},
		primaryClass={cs.RO},
		url={https://arxiv.org/abs/2502.01828}, 
  
}</code></pre>
  </div>
</section> -->



<footer class="footer">
  <div class="container">
<!--
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
-->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">NeRFies</a>.
			</p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
